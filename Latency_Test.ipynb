{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fangyuan-ksgk/ChatBot_Experiments/blob/main/Latency_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. **Dependency & Installation**"
      ],
      "metadata": {
        "id": "fsC-cRNZorFC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "237e77a8-0bf7-4131-9988-65f91acd6f42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'OpenVoice'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 211 (delta 90), reused 85 (delta 85), pack-reused 103\u001b[K\n",
            "Receiving objects: 100% (211/211), 2.28 MiB | 15.66 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n",
            "/content/OpenVoice\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 121671 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "4564e6|\u001b[1;32mOK\u001b[0m  |   456MiB/s|/content/checkpoints_1226.zip\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "Archive:  /content/checkpoints_1226.zip\n",
            "   creating: checkpoints/\n",
            "   creating: checkpoints/converter/\n",
            "  inflating: checkpoints/converter/config.json  \n",
            "  inflating: checkpoints/converter/checkpoint.pth  \n",
            "   creating: checkpoints/base_speakers/\n",
            "   creating: checkpoints/base_speakers/ZH/\n",
            "  inflating: checkpoints/base_speakers/ZH/config.json  \n",
            "  inflating: checkpoints/base_speakers/ZH/checkpoint.pth  \n",
            "  inflating: checkpoints/base_speakers/ZH/zh_default_se.pth  \n",
            "   creating: checkpoints/base_speakers/EN/\n",
            "  inflating: checkpoints/base_speakers/EN/config.json  \n",
            "  inflating: checkpoints/base_speakers/EN/en_style_se.pth  \n",
            "  inflating: checkpoints/base_speakers/EN/en_default_se.pth  \n",
            "  inflating: checkpoints/base_speakers/EN/checkpoint.pth  \n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m745.0/745.0 kB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for faster-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for eng-to-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/OpenVoice\n",
        "%cd /content/OpenVoice\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/OpenVoice/resolve/main/checkpoints_1226.zip -d /content -o checkpoints_1226.zip\n",
        "!unzip /content/checkpoints_1226.zip\n",
        "\n",
        "!pip install -q gradio==3.50.2 langid faster-whisper whisper-timestamped unidecode eng-to-ipa pypinyin cn2an\n",
        "\n",
        "import locale\n",
        "# WorkAround\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "locale.getpreferredencoding()\n",
        "# !pip install sounddevice\n",
        "!sudo apt-get install libportaudio2\n",
        "!pip install sounddevice\n",
        "\n",
        "# !python openvoice_app.py --share"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Mistral Model Loading** : mistral-7B-Instruct-v0.2"
      ],
      "metadata": {
        "id": "bXD9ob-7o1XC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mistral inference\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "device = \"cuda\" # the device to load the model onto\n",
        "\n",
        "llm = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
      ],
      "metadata": {
        "id": "GwZOkkDyV00G",
        "outputId": "846b03e5-ae3c-48ee-bffc-07ebd2d55fa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c05706e788e94df29be88adcb41ef120",
            "d4e06340ce6f47959cc232ee49c76c24",
            "1da2dd1fd2b54db48926a288861a50db",
            "735bb13a0a154ce1882965e49ae1f744",
            "fd441289c4194912bc117ea01a90fcbc",
            "24f425fe2cb2430e9ea2ac436cfd60e6",
            "75bbadbd52a84220a740bc1fcd789bc7",
            "78421e7210a3475d86ab68fb10a867f4",
            "43d90faf1fb140909b929938c8bd9ed7",
            "3179cc527457429fb3c6aa6174213f44",
            "3b857f65985541c6bede3784fc2fbe40"
          ]
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c05706e788e94df29be88adcb41ef120"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dirty Implementaion on-the-cloud\n",
        "* Need to use my Alienware Gadget for this one"
      ],
      "metadata": {
        "id": "LMQ7f5HidNbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import se_extractor\n",
        "from api import BaseSpeakerTTS, ToneColorConverter\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "def text_to_text(user_text, llm=llm):\n",
        "  messages = [\n",
        "      {\"role\": \"user\", \"content\": \"Hello.\"},\n",
        "      {\"role\": \"assistant\", \"content\": \"Hello.\"},\n",
        "      {\"role\": \"user\", \"content\": user_text}\n",
        "  ]\n",
        "\n",
        "  start = time.time()\n",
        "  encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "\n",
        "  model_inputs = encodeds.to(device)\n",
        "  llm.to(device)\n",
        "\n",
        "  generated_ids = llm.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "  decoded = tokenizer.batch_decode(generated_ids)\n",
        "  end = time.time()\n",
        "  print('----'*10)\n",
        "  print('Mistral 7B Processing Time: ', end-start)\n",
        "  print(decoded[0])\n",
        "  print('----'*10)\n",
        "\n",
        "  text = decoded[0].split('[/INST]')[-1].replace('\\n', '')\n",
        "  return text\n",
        "\n",
        "def text_to_speech(text, output_name='output_en_default'):\n",
        "  start = time.time()\n",
        "  ckpt_base = 'checkpoints/base_speakers/EN'\n",
        "  ckpt_converter = 'checkpoints/converter'\n",
        "  device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "  output_dir = 'outputs'\n",
        "\n",
        "  base_speaker_tts = BaseSpeakerTTS(f'{ckpt_base}/config.json', device=device)\n",
        "  base_speaker_tts.load_ckpt(f'{ckpt_base}/checkpoint.pth')\n",
        "\n",
        "  tone_color_converter = ToneColorConverter(f'{ckpt_converter}/config.json', device=device)\n",
        "  tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')\n",
        "\n",
        "  os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "  source_se = torch.load(f'{ckpt_base}/en_default_se.pth').to(device)\n",
        "\n",
        "  reference_speaker = 'resources/example_reference.mp3'\n",
        "  target_se, audio_name = se_extractor.get_se(reference_speaker, tone_color_converter, target_dir='processed', vad=True)\n",
        "\n",
        "  save_path = f'{output_dir}/{output_name}.wav'\n",
        "\n",
        "  # Run the base speaker tts\n",
        "  # src_path = f'{output_dir}/tmp.wav'\n",
        "  src_path = f'{output_dir}/Elon-Audio.wav'\n",
        "  base_speaker_tts.tts(text, src_path, speaker='default', language='English', speed=1.0)\n",
        "\n",
        "  # Run the tone color converter\n",
        "  encode_message = \"@MyShell\"\n",
        "  tone_color_converter.convert(\n",
        "      audio_src_path=src_path,\n",
        "      src_se=source_se,\n",
        "      tgt_se=target_se,\n",
        "      output_path=save_path,\n",
        "      message=encode_message)\n",
        "\n",
        "  end = time.time()\n",
        "  print('----'*10)\n",
        "  print('OpenVoice Text2Speech Time: ', end-start)\n",
        "  print('----'*10)\n",
        "\n",
        "def speech_to_text(audio_name):\n",
        "  start = time.time()\n",
        "  model_size = \"large-v3\"\n",
        "  # Run on GPU with FP16\n",
        "  model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "  segments, info = model.transcribe(f\"outputs/{audio_name}.wav\", beam_size=5)\n",
        "\n",
        "  print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
        "\n",
        "  text = ''\n",
        "  for segment in segments:\n",
        "    text += segment.text\n",
        "    print(\"Speech Time [%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
        "  end = time.time()\n",
        "  print('----'*10)\n",
        "  print('Faster-Whisper Speech2Text: ', end-start)\n",
        "  print('----'*10)\n",
        "  return text"
      ],
      "metadata": {
        "id": "eJT6PYakasYL"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A100 (80GB) Statistics:\n",
        "* Faster-Whisper (Speech2Text): 4.98 s\n",
        "* Mistral-7B (non-quantized): 9.8 s\n",
        "* OpenVoice (Text2Speech): 5.22 s\n",
        "\n",
        "Note that here the Time is completion time, in practice, latency is the time-till-first response. || My guess is some tricks are played in Kris's repo which reduces latency significantly."
      ],
      "metadata": {
        "id": "wKCHj9E2pzGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = speech_to_text('Elon-Audio') # MicroPhone input\n",
        "response = text_to_text(text) # Mistral Inferece\n",
        "speech = text_to_speech(response, 'response-audio') # Mistral Inferece"
      ],
      "metadata": {
        "id": "BUfKgvgTeDB4",
        "outputId": "3cbc1120-6433-4c77-d88a-ea7dc5773881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language 'en' with probability 1.000000\n",
            "Speech Time [0.00s -> 4.50s]  Elon Musk is a controversial figure and people's feelings towards him are quite diverse.\n",
            "Speech Time [5.00s -> 9.32s]  Some view him as a visionary and an innovator, admiring his entrepreneurial spirit,\n",
            "Speech Time [9.82s -> 14.06s]  his tenacity, and his ability to bring groundbreaking technologies to market.\n",
            "Speech Time [14.62s -> 19.28s]  Others criticize him for his unconventional business practices, his sometimes erratic\n",
            "Speech Time [19.28s -> 24.22s]  behavior, and his apparent disregard for conventional wisdom or established rules.\n",
            "Speech Time [24.56s -> 29.36s]  Musk's public persona is often the subject of intense scrutiny, and there are those who\n",
            "Speech Time [29.36s -> 32.50s]  appreciate his brashness and those who find it off-potting.\n",
            "Speech Time [32.98s -> 37.40s]  His tweets, in particular, have been known to cause controversy, with some seeing them\n",
            "Speech Time [37.40s -> 42.34s]  as a source of entertainment and others as evidence of impulsivity or lack of professionalism.\n",
            "Speech Time [42.76s -> 47.80s]  Ultimately, people's feelings about Musk come down to their individual perspectives and values.\n",
            "Speech Time [48.28s -> 52.42s]  Some admire his ambition and his drive to push the boundaries of what is possible,\n",
            "Speech Time [52.50s -> 57.48s]  while others criticize him for his perceived arrogance and his disregard for traditional\n",
            "Speech Time [57.48s -> 58.36s]  business norms.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech Time [58.36s -> 63.52s]  One thing is certain Musk is a polarizing figure and his impact on the world of business.\n",
            "Speech Time [64.02s -> 69.06s]  Technology and transportation is undeniable whether you view him as a visionary or a disruptor.\n",
            "----------------------------------------\n",
            "Faster-Whisper Speech2Text:  4.984947204589844\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "Mistral 7B Processing Time:  9.861910581588745\n",
            "<s> [INST] Hello. [/INST]Hello.</s> [INST]  Elon Musk is a controversial figure and people's feelings towards him are quite diverse. Some view him as a visionary and an innovator, admiring his entrepreneurial spirit, his tenacity, and his ability to bring groundbreaking technologies to market. Others criticize him for his unconventional business practices, his sometimes erratic behavior, and his apparent disregard for conventional wisdom or established rules. Musk's public persona is often the subject of intense scrutiny, and there are those who appreciate his brashness and those who find it off-potting. His tweets, in particular, have been known to cause controversy, with some seeing them as a source of entertainment and others as evidence of impulsivity or lack of professionalism. Ultimately, people's feelings about Musk come down to their individual perspectives and values. Some admire his ambition and his drive to push the boundaries of what is possible, while others criticize him for his perceived arrogance and his disregard for traditional business norms. One thing is certain Musk is a polarizing figure and his impact on the world of business. Technology and transportation is undeniable whether you view him as a visionary or a disruptor. [/INST] You're absolutely right. Elon Musk is a complex and controversial figure who elicits strong reactions from people. Some view him as a visionary entrepreneur who is pushing the boundaries of innovation and making groundbreaking advancements in various industries, particularly in technology and transportation. Others see him as a disruptor who ignores traditional business practices and norms, and whose unconventional methods and erratic behavior raise concerns.\n",
            "\n",
            "Musk's public persona is certainly a subject of intense scrutiny, with his tweets being a particular point of scrutiny for some. Some people find his tweets entertaining, while others view them as evidence of impulsivity or lack of professionalism. Ultimately, people's opinions of Musk depend on their individual perspectives and values. Some admire his ambition and drive to push the boundaries of what is possible, while others criticize him for his perceived arrogance and disregard for established rules.\n",
            "\n",
            "There is no denying that Musk has had a significant impact on the world of business, technology, and transportation. Whether you view him as a visionary or a disruptor, he has certainly left a mark on the industries he has entered, and his innovations and technologies have the potential to shape the future.</s>\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded checkpoint 'checkpoints/base_speakers/EN/checkpoint.pth'\n",
            "missing/unexpected keys: [] []\n",
            "Loaded checkpoint 'checkpoints/converter/checkpoint.pth'\n",
            "missing/unexpected keys: [] []\n",
            " > Text splitted to sentences.\n",
            "You're absolutely right. Elon Musk is a complex and controversial figure who elicits strong reactions from people.\n",
            "Some view him as a visionary entrepreneur who is pushing the boundaries of innovation and making groundbreaking advancements in various industries,\n",
            "particularly in technology and transportation. Others see him as a disruptor who ignores traditional business practices and norms,\n",
            "and whose unconventional methods and erratic behavior raise concerns. Musk's public persona is certainly a subject of intense scrutiny,\n",
            "with his tweets being a particular point of scrutiny for some.\n",
            "Some people find his tweets entertaining, while others view them as evidence of impulsivity or lack of professionalism.\n",
            "Ultimately, people's opinions of Musk depend on their individual perspectives and values.\n",
            "Some admire his ambition and drive to push the boundaries of what is possible,\n",
            "while others criticize him for his perceived arrogance and disregard for established rules.\n",
            "There is no denying that Musk has had a significant impact on the world of business,\n",
            "technology, and transportation. Whether you view him as a visionary or a disruptor,\n",
            "he has certainly left a mark on the industries he has entered,\n",
            "and his innovations and technologies have the potential to shape the future. /s\n",
            " > ===========================\n",
            "jʊɹ ˌæbsəˈlutli ɹaɪt. elon* məsk ɪz ə ˈkɑmplɛks ənd ˌkɑntɹəˈvəɹʃəɫ ˈfɪgjəɹ hu ɪˈlɪsəts stɹɔŋ ɹiˈækʃənz fɹəm ˈpipəɫ.\n",
            " length:115\n",
            " length:115\n",
            "səm vju ɪm ɛz ə ˈvɪʒəˌnɛɹi ˌɑntɹəpɹəˈnʊɹ hu ɪz ˈpʊʃɪŋ ðə ˈbaʊndəɹiz əv ˌɪnəˈveɪʃən ənd ˈmeɪkɪŋ ˈgɹaʊnˌbɹeɪkɪŋ ədˈvænsmənts ɪn ˈvɛɹiəs ˈɪndəstɹiz,\n",
            " length:145\n",
            " length:145\n",
            "ˌpɑɹˈtɪkjələɹli ɪn tɛkˈnɑlədʒi ənd ˌtɹænspəɹˈteɪʃən. ˈəðəɹz si ɪm ɛz ə disɹuptoɹ* hu ˌɪgˈnɔɹz tɹəˈdɪʃənəɫ ˈbɪznɪs ˈpɹæktɪsɪz ənd nɔɹmz,\n",
            " length:135\n",
            " length:135\n",
            "ənd huz ˌənkənˈvɛnʃənəɫ ˈmɛθədz ənd ɪˈɹætɪk bɪˈheɪvjəɹ ɹeɪz kənˈsəɹnz. musk's* ˈpəblɪk pəɹˈsoʊnə ɪz ˈsəɹtənli ə ˈsəbdʒɪkt əv ˌɪnˈtɛns ˈskɹutəni,\n",
            " length:144\n",
            " length:143\n",
            "wɪθ hɪz tweets* biɪŋ ə ˌpɑˈtɪkjələɹ pɔɪnt əv ˈskɹutəni fəɹ səm.\n",
            " length:63\n",
            " length:63\n",
            "səm ˈpipəɫ faɪnd hɪz tweets* ˌɛnəɹˈteɪnɪŋ, waɪɫ ˈəðəɹz vju ðɛm ɛz ˈɛvədəns əv impulsivity* əɹ læk əv pɹəˈfɛʃənəˌlɪzəm.\n",
            " length:118\n",
            " length:118\n",
            "ˈəltəmətli, ˈpipəɫz əˈpɪnjənz əv məsk dɪˈpɛnd ɔn ðɛɹ ˌɪndəˈvɪdʒəwəɫ pəɹˈspɛktɪvz ənd ˈvæljuz.\n",
            " length:93\n",
            " length:93\n",
            "səm ædˈmaɪɹ hɪz æmˈbɪʃən ənd dɹaɪv tɪ pʊʃ ðə ˈbaʊndəɹiz əv wət ɪz ˈpɑsəbəɫ,\n",
            " length:75\n",
            " length:75\n",
            "waɪɫ ˈəðəɹz ˈkɹɪtɪˌsaɪz ɪm fəɹ hɪz pəɹˈsivd ˈɛɹəgəns ənd ˌdɪsɹɪˈgɑɹd fəɹ ɪˈstæblɪʃt ɹuɫz.\n",
            " length:89\n",
            " length:89\n",
            "ðɛɹ ɪz noʊ dɪˈnaɪɪŋ ðət məsk həz hæd ə sɪgˈnɪfɪkənt ˌɪmˈpækt ɔn ðə wəɹɫd əv ˈbɪznɪs,\n",
            " length:84\n",
            " length:84\n",
            "tɛkˈnɑlədʒi, ənd ˌtɹænspəɹˈteɪʃən. ˈwɛðəɹ ju vju ɪm ɛz ə ˈvɪʒəˌnɛɹi əɹ ə disɹuptoɹ*,\n",
            " length:84\n",
            " length:84\n",
            "hi həz ˈsəɹtənli lɛft ə mɑɹk ɔn ðə ˈɪndəstɹiz hi həz ˈɛnəɹd,\n",
            " length:60\n",
            " length:60\n",
            "ənd hɪz ˌɪnəˈveɪʃənz ənd tɛkˈnɑlədʒiz hæv ðə pəˈtɛnʃəɫ tɪ ʃeɪp ðə fˈjutʃəɹ. /ɛs.\n",
            " length:80\n",
            " length:79\n",
            "----------------------------------------\n",
            "OpenVoice Text2Speech Time:  5.224689960479736\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j5Hr8BvIdn0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hs13xCbTdn73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1UDcKiH4ZH3K"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5DUgpGDrRYqF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e-seSjvIQ9vt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c05706e788e94df29be88adcb41ef120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4e06340ce6f47959cc232ee49c76c24",
              "IPY_MODEL_1da2dd1fd2b54db48926a288861a50db",
              "IPY_MODEL_735bb13a0a154ce1882965e49ae1f744"
            ],
            "layout": "IPY_MODEL_fd441289c4194912bc117ea01a90fcbc"
          }
        },
        "d4e06340ce6f47959cc232ee49c76c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24f425fe2cb2430e9ea2ac436cfd60e6",
            "placeholder": "​",
            "style": "IPY_MODEL_75bbadbd52a84220a740bc1fcd789bc7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1da2dd1fd2b54db48926a288861a50db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78421e7210a3475d86ab68fb10a867f4",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43d90faf1fb140909b929938c8bd9ed7",
            "value": 3
          }
        },
        "735bb13a0a154ce1882965e49ae1f744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3179cc527457429fb3c6aa6174213f44",
            "placeholder": "​",
            "style": "IPY_MODEL_3b857f65985541c6bede3784fc2fbe40",
            "value": " 3/3 [00:02&lt;00:00,  1.26it/s]"
          }
        },
        "fd441289c4194912bc117ea01a90fcbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24f425fe2cb2430e9ea2ac436cfd60e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75bbadbd52a84220a740bc1fcd789bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78421e7210a3475d86ab68fb10a867f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d90faf1fb140909b929938c8bd9ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3179cc527457429fb3c6aa6174213f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b857f65985541c6bede3784fc2fbe40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}